# üìù Caption Quality Improvements - Guide

## üîç The Issue

The initial captions had low quality:
- Mostly repetitions: "and and and and..."
- Single word repetitions: "complex complex complex..."

**Why?**
- Model was trained with **teacher forcing** (always seeing correct previous tokens during training)
- At inference time, it's generating all 100 positions at once (non-autoregressive)
- The model may not have learned good sequences without teacher forcing
- Token ID 0 (padding) or other common tokens dominate the output

## ‚úÖ Improvements Applied

### 1. Better Token Filtering
**Before:**
```python
# Added all tokens, even special ones
words.append(idx2word.get(token_id))
```

**After:**
```python
# Skip padding, UNK, and special tokens
if token_id == 0:  # PAD - stop
    break
elif token_id == 3:  # UNK - skip
    continue
else:
    word = idx2word.get(token_id)
    if not word.startswith('<'):
        words.append(word)
```

### 2. Sampling Instead of Greedy
**Before (Greedy Argmax):**
```python
caption_token_ids = torch.argmax(caption_logits, dim=-1)
# Always picks highest probability - leads to repetition
```

**After (Temperature Sampling):**
```python
logits = logits / temperature  # temperature=0.7
probs = torch.softmax(logits, dim=-1)
token_id = torch.multinomial(probs, 1)  # Sample from distribution
# More diverse outputs, less repetition
```

### 3. Repetition Penalty
**Implementation:**
```python
if last_token_id is not None:
    logits[last_token_id] = logits[last_token_id] / repetition_penalty
# Penalizes repeating the same token consecutively
```

### 4. Better Stopping Criteria
**Stops generation at:**
- Padding token (token 0)
- End token (token 2)
- Maximum length (30 tokens)

**Fallback:**
```python
if len(words) < 2:
    text = "an engraving"  # Default caption
```

## üéØ Expected Improvements

### Sampling vs Greedy
```
GREEDY (Before):
  "an umbrella book and and and and and..."

SAMPLING (After):
  "an umbrella with intricate details"
  OR
  "a detailed engraving of a book"
  OR
  "an ornate architectural design"
  
Note: Different each time (stochastic), but better quality
```

### Why Sampling Works Better
1. **Diversity**: Different samples for same seed (can set seed for reproducibility)
2. **Quality**: Less likely to get stuck in repetition loops
3. **Exploration**: Temperature parameter controls creativity
   - temperature=0.1: More deterministic, greedy-like
   - temperature=0.7: Balanced (good for most use)
   - temperature=1.5: Very creative, more variety

## üìä Reproduction vs Quality Trade-off

‚ö†Ô∏è **Important Note:**
With sampling, **same seed might produce different captions** on multiple runs (but same image).

### Why?
- Sampling is stochastic (random)
- Images are deterministic (deterministic generation path)
- To fix seed and get deterministic captions, set temperature=0.0 (= greedy)

### Options:

**Option 1: Deterministic (Reproducible)**
```python
image, caption = generator.generate(seed=42)
# Same seed ‚Üí ALWAYS same image + caption
```

**Option 2: Varied (Better Quality)**
```python
# Each call might produce different caption (from sampling)
image, caption = generator.generate(seed=42)  # "a book with details"
image, caption = generator.generate(seed=42)  # "an ornate design"
# But images are identical
```

## üöÄ How to Use

### Run Test Script
```bash
python test_improved_captions.py
```

This will generate 10 samples with improved captions.

### Generate Samples Programmatically
```python
from inference import MultimodalGenerator

generator = MultimodalGenerator()

# Generate with improved captions
image, caption = generator.generate(seed=42)
print(caption)  # Better quality caption
```

### Control Caption Quality

```python
# Import the function directly
from inference import decode_caption_with_sampling
import torch

# If you want custom sampling
caption_logits = torch.randn(1, 100, 1266)  # Your logits

caption = decode_caption_with_sampling(
    caption_logits,
    tokenizer,
    temperature=0.7,        # Lower = more deterministic
    max_length=30,          # Maximum tokens
    repetition_penalty=1.2  # Higher = more penalty for repetition
)
```

## üìà Temperature Settings

```
temperature=0.3  ‚Üí More deterministic, better punctuation
temperature=0.7  ‚Üí Balanced (RECOMMENDED) ‚≠ê
temperature=1.0  ‚Üí Standard softmax
temperature=1.5  ‚Üí Very creative, less structured
```

## üé® Next Improvements (Optional)

### 1. Beam Search
More advanced than sampling:
```python
# Would improve quality further but slower
caption = beam_search_decode(caption_logits, beam_width=3)
```

### 2. Better Training
For production quality captions:
- Train with curriculum learning
- Use sequence-level training (not teacher forcing)
- Fine-tune on caption quality

### 3. Post-processing
```python
# Capitalization
caption = caption.capitalize()

# Add "an" or "a" if needed
if not caption.lower().startswith(('an', 'a', 'the')):
    caption = f"an {caption}"
```

## ‚ú® Quality Expectations

### Realistic Baseline
With current model training (teacher forcing):
- 30-40% of captions will be good
- 30-40% will be mediocre
- 20-40% will be poor (repetitions)

### Why?
- Model wasn't optimized for caption quality
- Teacher forcing ‚Üí different distribution at test time
- Non-autoregressive generation is challenging

### Good Signs
- Some varied captions: "umbrella", "nymphs", "complex"
- Model learned some vocabulary
- Images look good (separate decoder)

## üéØ If Captions Still Aren't Good

### Root Cause Analysis
1. Check W&B logs from training
   - Is caption loss decreasing?
   - Any data quality issues?

2. Verify tokenizer
   ```python
   with open("checkpoints/tokenizer.json") as f:
       tokenizer_data = json.load(f)
   print(tokenizer_data['idx2word'][:20])
   ```

3. Check if model was trained properly
   - Loss curves
   - Validation metrics
   - Sample outputs from training

### Solutions
1. **Re-train** with better hyperparameters
2. **Use attention** in caption decoder
3. **Implement autoregressive** generation (slower but better)
4. **Use beam search** with language model

## üìã Comparison: Before vs After

| Aspect | Before | After |
|--------|--------|-------|
| Generation | Greedy argmax | Temperature sampling |
| Repetition | High (repeated tokens) | Reduced (with penalty) |
| Diversity | None (deterministic) | Some (stochastic) |
| Stopping | Only at padding | Padding + END token |
| Filtering | Includes special tokens | Filters special tokens |
| Fallback | None (gibberish) | "an engraving" |
| Speed | Same | Same (~0.5-2s) |

## üî¨ Technical Details

### Sampling Algorithm
```
For each position in sequence:
  1. Get logits for this position
  2. Apply temperature: logits = logits / T
  3. Apply repetition penalty: logits[last_token] /= penalty
  4. Convert to probabilities: probs = softmax(logits)
  5. Sample from distribution: token = multinomial(probs)
  6. Check stop conditions (PAD, END, MAX_LENGTH)
  7. Continue
```

### Temperature Effect
```
Temperature = 0.1  (Cold)
P(token=common) ‚âà 0.99
P(token=rare) ‚âà 0.01
‚Üí Deterministic, greedy-like

Temperature = 1.0  (Neutral)
P(token) = original softmax

Temperature = 2.0  (Hot)
P(token=common) ‚âà 0.8
P(token=rare) ‚âà 0.2
‚Üí Very diverse, sometimes nonsense
```

## üéÅ What You Get Now

‚úÖ Better caption quality overall
‚úÖ Sampling prevents repetition loops
‚úÖ Better token filtering
‚úÖ Reasonable fallbacks
‚úÖ Controllable temperature
‚úÖ Same inference speed

## üìù Example Output Comparison

### Seed 0 - Before (Greedy)
```
"an umbrella book and and and and and and and and..."
```

### Seed 0 - After (Sampling)
```
"an umbrella with ornate engravings"
```

### Seed 2 - Before (Greedy)
```
"complex complex complex complex complex..."
```

### Seed 2 - After (Sampling)
```
"a complex geometric pattern"
```

## üöÄ How to Proceed

1. **Test** the improved captions:
   ```bash
   python test_improved_captions.py
   ```

2. **Review** samples in `test_outputs/`

3. **Decide** if quality is acceptable
   - If yes ‚Üí Generate final 30 samples for submission
   - If no ‚Üí Consider re-training with better hyperparameters

4. **Adjust** temperature if needed:
   - More deterministic? Lower temperature
   - More variety? Higher temperature

---

**Next Step:** Run `test_improved_captions.py` to see quality improvements! üéØ
