â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    W&B TRAINING - START HERE                                â•‘
â•‘                                                                              â•‘
â•‘  Complete setup for rigorous multimodal model training with metrics logging  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ“¥ STEP 1: DOWNLOAD THESE FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

From /mnt/user-data/outputs/:
  âœ“ train_wandb.py                    â† Main training script with W&B
  âœ“ model_architecture_large.py       â† Model (already have)
  âœ“ WANDB_QUICKSTART.md               â† 5-minute setup guide
  âœ“ WANDB_GUIDE.md                    â† Detailed reference
  âœ“ WANDB_COMPLETE_GUIDE.md           â† Everything explained

Copy to: ~/Documents/dashverse/


ğŸ› ï¸ STEP 2: INSTALL DEPENDENCIES (First Time Only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Run in terminal:
  pip install wandb psutil GPUtil

Verify:
  python -c "import wandb, psutil, GPUtil; print('âœ“ Ready')"


ğŸŒ STEP 3: CREATE W&B ACCOUNT & LOGIN (First Time Only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Go to: https://wandb.ai/signup
2. Create account (free tier is fine)
3. Verify email
4. Get API key from: https://wandb.ai/settings/profile
5. In terminal, run:
     wandb login
   Paste API key when prompted

Result: "âœ“ Successfully authenticated"


ğŸš€ STEP 4: CUSTOMIZE CONFIG (Optional)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Edit ~/Documents/dashverse/train_wandb.py

Find this section:
  class Config:
      batch_size = 16              â† Adjust for your GPU
      num_epochs = 100             â† Or 50 for quick test
      learning_rate = 1e-3

For H100 80GB: Keep batch_size=16 or increase to 32
For RTX 3090 24GB: Keep batch_size=8


â–¶ï¸ STEP 5: START TRAINING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

cd ~/Documents/dashverse
python train_wandb.py

You'll see:
  âœ“ Loading dataset...
  âœ“ Building tokenizer...
  âœ“ Creating data loaders...
  âœ“ Building model...
  âœ“ Setting up W&B...
  âœ“ W&B run initialized: https://wandb.ai/your-username/multimodal-engravings/runs/xxx


ğŸ“Š STEP 6: MONITOR IN REAL-TIME
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Copy the URL from console output
2. Open in web browser
3. Watch metrics update every batch:
   - Loss curves (should decrease)
   - Latent space statistics
   - Gradient norms
   - GPU memory usage
   - And more!

Refresh browser every 10 seconds to see live updates.


ğŸ“ˆ WHAT YOU'LL LOG
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Loss Components:        Latent Space:           Image Quality:
  loss_total              latent_mean             image_mse
  loss_image              latent_std              image_l1
  loss_caption            latent_norm           
  loss_alignment        
                        Captions:               Gradients:
Hardware:               caption_accuracy        grad_norm
  gpu_memory_percent      caption_perplexity     grad_mean
  gpu_memory_used         caption_entropy        grad_max
  cpu_percent           

Plus: Learning rate, batch size, epoch number, and more!


âœ… WHAT TO CHECK (After Training Starts)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After 5 epochs:
  âœ“ Is loss decreasing? YES â†’ Training is healthy!
  âœ“ Are gradients flowing? (grad_norm > 0) YES â†’ Good!
  âœ“ Is GPU being used? (gpu_memory_percent > 70%) YES â†’ Perfect!

After 20 epochs:
  âœ“ Loss decreased by 30%+?
  âœ“ Validation loss similar to training?
  âœ“ Latent space stabilizing?

After 100 epochs:
  âœ“ Analyze which loss component dominates
  âœ“ Check for overfitting (val_loss vs train_loss)
  âœ“ Review gradient health


ğŸ” RIGOROUS ANALYSIS QUESTIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Is my learning rate correct?
   â†’ Check grad_norm trend. Spikes? Reduce LR. Flat? Increase LR.

2. Which component is struggling?
   â†’ Check loss_image, loss_caption, loss_alignment separately
   â†’ Whichever is largest needs attention

3. Is the model overfitting?
   â†’ Compare train_loss vs val_loss
   â†’ Large gap (> 1.0)? Reduce model size or add regularization

4. Is GPU memory efficient?
   â†’ Check gpu_memory_percent
   â†’ < 60%? Can use larger batch. > 95%? Reduce batch!

5. Is vocabulary built correctly?
   â†’ Check console output for vocabulary size
   â†’ Ideal: 1000-5000 tokens (yours should be ~1266)


ğŸ“ OUTPUT FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After training completes:
  checkpoints/
    â”œâ”€â”€ best.pt              â† Use this for inference
    â”œâ”€â”€ epoch_000.pt         â† Earlier checkpoints
    â”œâ”€â”€ epoch_001.pt
    â””â”€â”€ tokenizer.json       â† Use this for encoding captions


ğŸ“š DOCUMENTATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  âš¡ WANDB_QUICKSTART.md        â†’ Get started in 5 minutes
  ğŸ“– WANDB_GUIDE.md             â†’ Detailed explanations & examples  
  ğŸ“˜ WANDB_COMPLETE_GUIDE.md    â†’ Everything you need to know
  ğŸ¨ model_architecture_large.py â†’ Model specs


ğŸ†˜ TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"wandb: offline"
  â†’ wandb online && wandb login

"No metrics appearing"
  â†’ Wait 60 seconds, refresh browser

"Out of memory"
  â†’ Reduce batch_size: change 16 â†’ 8

"Training too slow"
  â†’ Increase num_workers: change 4 â†’ 8
  â†’ Increase batch_size: change 16 â†’ 32


ğŸ¯ NEXT STEPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Run training for 20 epochs to verify everything works
2. Check W&B dashboard to ensure metrics are being logged
3. Adjust hyperparameters based on observed metrics
4. Run full training (100 epochs) with optimized settings
5. Export results and analyze findings
6. Compare multiple runs to find optimal configuration
7. Use best model for inference


ğŸ’¡ PRO TIPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â€¢ Log everything: More data = Better insights
â€¢ Run multiple experiments: Different batch sizes, learning rates
â€¢ Document findings: Add notes to W&B runs
â€¢ Compare runs: See which config works best
â€¢ Export metrics: Use in Excel/Python for further analysis
â€¢ Share dashboard: W&B URLs can be shared with team


ğŸš€ YOU'RE READY!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

All files are prepared. Everything is configured. Just run:

    cd ~/Documents/dashverse
    python train_wandb.py

Then open the W&B URL in your browser and watch training in real-time!


Questions?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ WANDB_QUICKSTART.md    (5-minute setup)
âœ“ WANDB_GUIDE.md        (detailed reference)
âœ“ WANDB_COMPLETE_GUIDE.md (everything explained)

All files are in /mnt/user-data/outputs/

Happy training! ğŸ‰ğŸ“Š
